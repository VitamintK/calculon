{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#x = pd.read_csv(\"len40_mask3.txt\", header=None, delim_whitespace=True, dtype=str, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = 40\n",
    "vocab_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (text_length, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le = LabelEncoder()\n",
    "#categorical = le.fit_transform(x.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i for i in x.values.flatten() if not isinstance(i, str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = Tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.fit_on_sequences(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.sequences_to_matrix([[\"Hello\", \"this\", \"is\", \"test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.word_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer(filters='\\n', num_words=vocab_size) #try setting vocab_size to 2000 or 4000 if training not working\n",
    "with open(\"len40.txt\") as f:\n",
    "    t.fit_on_texts([f.read(), '<m>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "with open(\"len40_mask3.txt\") as f:\n",
    "    for line in f:\n",
    "        X.append(t.texts_to_sequences([line])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) #turn our data from python list of lists into np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled = []\n",
    "with open(\"len40.txt\") as f:\n",
    "    for line in f:\n",
    "        X_filled.append(t.texts_to_sequences([line])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled = np.array(X_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import Counter\n",
    "#Counter([len(p) for p in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OHE = OneHotEncoder()\n",
    "OHE.fit(np.array(list(t.word_index.values())).reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE.transform(X_filled[0].reshape((-1,1))).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, t.word_index.items())) #turn our numbers into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-1d51eab0c643>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mreverse_word_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int32' object is not iterable"
     ]
    }
   ],
   "source": [
    "[reverse_word_map[i] for i in X[0]] #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vocab_size is None:\n",
    "    vocab_size = len(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.add(Embedding(vocab_size, 300, input_length=text_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.add(Bidirectional(LSTM(300, return_sequences=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.add(TimeDistributed(Dense(vocab_size, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.add(Embedding(vocab_size, 300, input_length=text_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input_g = Input(shape=(text_length,vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_layer = Embedding(vocab_size, 300, input_length=text_length)\n",
    "embedding_layer = TimeDistributed(Dense(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embedding_layer(main_input_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Bidirectional(LSTM(300, return_sequences=True))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_output_g = TimeDistributed(Dense(vocab_size, activation='softmax'))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model = Model(inputs=[main_input_g], outputs=[main_output_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40, 97491)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 300)           29247600  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40, 600)           1442400   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 40, 97491)         58592091  \n",
      "=================================================================\n",
      "Total params: 89,282,091\n",
      "Trainable params: 89,282,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input_d = Input(shape=(text_length,vocab_size))\n",
    "aux_input_d = Input(shape=(text_length,vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_in = embedding_layer(main_input_d)\n",
    "context = embedding_layer(aux_input_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = Concatenate(axis=-1)([filled_in, context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Bidirectional(LSTM(300, return_sequences=True))(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_output_d = TimeDistributed(Dense(1, activation='sigmoid'))(x) #or sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model = Model(inputs = [main_input_d, aux_input_d], outputs=[main_output_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 40, 97491)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 40, 97491)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 40, 300)      29247600    input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 40, 600)      0           time_distributed_1[3][0]         \n",
      "                                                                 time_distributed_1[4][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 40, 600)      2162400     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 40, 1)        601         bidirectional_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 31,410,601\n",
      "Trainable params: 31,410,601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 40, 97491)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 40, 97491)    89282091    input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 40, 1)        31410601    model_1[3][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 91,445,092\n",
      "Trainable params: 91,445,092\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#AM = Sequential()\n",
    "optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "AM_input = Input(shape=(text_length,vocab_size))\n",
    "generator_output = generator_model(AM_input)\n",
    "discriminator_output = discriminator_model([generator_output, AM_input])\n",
    "AM = Model(inputs=[AM_input], outputs=discriminator_output)\n",
    "#AM.add(discriminator_model)\n",
    "AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "    metrics=['accuracy'])\n",
    "AM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def train(train_steps=2000, batch_size=10, save_interval=1):\n",
    "    def categorical_to_one_hot(categorical):\n",
    "        return OHE.transform(categorical.reshape(batch_size*text_length,1)).toarray().reshape(batch_size,text_length,-1)\n",
    "    noise_input = None\n",
    "    if save_interval>0:\n",
    "        noise_input = np.random.normal(0, 1, size=[16, 100])\n",
    "    for i in range(train_steps):\n",
    "        if i%2 == 0:\n",
    "            gc.collect()\n",
    "        indices_fake = np.random.randint(0, X.shape[0], size=batch_size)\n",
    "        fake_unfilled = X[indices_fake, :]\n",
    "        #noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "        fake_unfilled = categorical_to_one_hot(fake_unfilled)\n",
    "        fake_filled = generator_model.predict(fake_unfilled)\n",
    "\n",
    "        indices_real = np.random.randint(0, X.shape[0], size=batch_size)\n",
    "        real_unfilled = X[indices_real, :]\n",
    "        real_filled = X_filled[indices_real, :]\n",
    "        real_unfilled = categorical_to_one_hot(real_unfilled)\n",
    "        real_filled = categorical_to_one_hot(real_filled)\n",
    "        \n",
    "        x_unfilled = np.concatenate((real_unfilled, fake_unfilled))\n",
    "        x_filled = np.concatenate((real_filled, fake_filled))\n",
    "        y = np.ones([2*batch_size, text_length, 1])\n",
    "        y[batch_size:, :, :] = 0\n",
    "        d_loss = discriminator_model.train_on_batch([x_filled, x_unfilled], y)\n",
    "        #above here is training the discriminator (DM)\n",
    "        #under here is training the generator (AM)\n",
    "        for j in range(10):\n",
    "            y = np.ones([batch_size, text_length, 1])\n",
    "            #noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "            indices_fake = np.random.randint(0, X.shape[0], size=batch_size)\n",
    "            fake_unfilled = X[indices_fake, :]\n",
    "            fake_unfilled = categorical_to_one_hot(fake_unfilled)\n",
    "            a_loss = AM.train_on_batch(fake_unfilled, y)\n",
    "            if a_loss[0] < 1.8:\n",
    "                break\n",
    "        log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "        log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "        print(log_mesg)\n",
    "        if save_interval>0:\n",
    "            if (i+1)%save_interval==0:\n",
    "                print_examples(indices_fake, fake_filled, fake_unfilled, save2file=True)#samples=noise_input.shape[0],\\\n",
    "                    #noise=noise_input, step=(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(indices_fake, fake_filled, fake_unfilled, save2file = False, ):\n",
    "    batch_size = 10\n",
    "    def categorical_to_one_hot(categorical):\n",
    "        return OHE.transform(categorical.reshape(batch_size*text_length,1)).toarray().reshape(batch_size,text_length,-1)\n",
    "\n",
    "    print(' '.join([reverse_word_map.get(OHE.active_features_[np.argmax(i)], '<m>') for i in fake_filled[0]]))\n",
    "    print(' '.join([reverse_word_map.get(i) for i in X_filled[indices_fake][0]]))\n",
    "    print(' '.join([reverse_word_map.get(i) for i in X[indices_fake][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: [D loss: 0.211680, acc: 0.910000]  [A loss: 1.156378, acc: 0.402500]\n",
      "the the the is the is is is is is is is is is is now is is is is is is is is is is is is is is is is is is is is is is is is\n",
      "of them hold me down while i 'm pressin you eos so who stressin who , and even though my nigga gone eos lil ' kim and puff daddy keep keepin it on eos chorus eos verse three : puff\n",
      "of them hold me <m> while i 'm pressin you eos so who stressin who , <m> even <m> my nigga gone eos lil ' kim and puff daddy keep keepin it on eos chorus eos verse three : puff\n",
      "0: [D loss: 0.537730, acc: 0.568750]  [A loss: 1.743441, acc: 0.000000]\n",
      "the the the the the is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is now is is\n",
      "up ! eos dealer ! stealer ! eos we walk the highwire eos we send our men to the front lines eos an ' we 're hoping that we backed the right side eos with hot guns and cold ,\n",
      "up ! <m> dealer ! stealer ! eos we walk the highwire eos we <m> our men to the front lines eos an <m> we 're hoping that we backed the right side eos with hot guns and cold ,\n",
      "0: [D loss: 0.273967, acc: 0.942500]  [A loss: 1.795981, acc: 0.032500]\n",
      "the the the the the is the is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is\n",
      "spring is here ! why does n't my heart go dancing ? eos spring is here ! why is n't the waltz entrancing ? eos no desire , no ambition leads me eos maybe it 's because nobody needs me\n",
      "spring is here ! why does n't <m> heart go dancing ? eos spring is <m> ! why <m> n't the waltz entrancing ? eos no desire , no ambition leads me eos maybe it 's because nobody needs me\n",
      "1: [D loss: 0.235513, acc: 0.920000]  [A loss: 1.290538, acc: 0.192500]\n",
      "the the the is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is\n",
      "this time we got it right ! ( yeah ) eos it 's been a long time , overtime eos second flash , you 're out of sight ( yeah , so get up ! ) eos turn your clock\n",
      "this time <m> got it right ! ( yeah ) <m> it 's been a long time , overtime eos second flash , you 're out of sight ( <m> , so get up ! ) eos turn your clock\n",
      "0: [D loss: 0.310224, acc: 0.771250]  [A loss: 1.455423, acc: 0.100000]\n",
      "the the the the the the the is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is\n",
      "quite diverting , even tender now and then eos remember i will always be the first to sing your praise eos but i must close the book on our adolescent days eos nothing can be permanent eos nothing set in\n",
      "<m> diverting <m> even tender now and then eos remember i will always be the first to sing your praise eos but i must close the book on our adolescent days eos nothing can be permanent eos <m> set in\n",
      "0: [D loss: 0.281534, acc: 0.842500]  [A loss: 1.655434, acc: 0.025000]\n",
      "the the the the the the the the the the the the is is is the the the the the is is is is is is is is is is is is is is is is is is is is\n",
      "what to do with mine '' eos all my kids already rich and they kids , and they kids eos they think money grow on trees and as tall as they grew i climbed eos knock knock `` who 's\n",
      "<m> to do with mine '' eos all my kids already rich and they kids , <m> <m> kids eos they think money grow on trees and as tall as they grew i climbed eos knock knock `` who 's\n",
      "0: [D loss: 0.325870, acc: 0.757500]  [A loss: 1.681074, acc: 0.000000]\n",
      "the the the the the the the the the the the the the the the the is is the the the is is is is is is is is is is is is is is is is is is is\n",
      "'s within you , it will never never ever let you down eos i 'm the way , i 'm the key to liberty and unity , are you listening eos chorus eos one hundred million voices singing ( can\n",
      "'s within you , it will never never ever let <m> down eos <m> 'm the way , i 'm the key to liberty and unity , are you listening eos chorus eos one hundred million <m> singing ( can\n",
      "1: [D loss: 0.265389, acc: 0.902500]  [A loss: 1.178218, acc: 0.147500]\n",
      "the the the the the the the the the the the the the the the the the the the the the is is is is is is is is is is is is is is is is is is is\n",
      "eos she says , hey now , wo n't you give it to eos wo n't you give it , give it , give it me , oh eos hey now , there 's a lovely girl eos give it\n",
      "eos she says , hey now , wo n't you give it to eos wo n't you give it , give it , <m> it <m> , oh eos <m> now , there 's a lovely girl eos give it\n",
      "0: [D loss: 0.395899, acc: 0.691250]  [A loss: 1.423906, acc: 0.002500]\n",
      "the the the the the the the the the the the the the the the the the the the the the the is is is is is is is is is is is is is is is is is is\n",
      "carry me safely into your arms eos there across the border eos for what are we eos without hope in our hearts eos that someday we 'll drink from god 's blessed waters eos and eat the fruit from the\n",
      "carry me safely into your arms eos there across the border <m> for what are we eos without hope in our hearts eos that someday we 'll drink from god <m> blessed <m> eos and eat the fruit from the\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "\n",
    "discriminator_model.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_hot_encoded_test = OHE.transform(fake_unfilled.reshape(400,1)).toarray().reshape(10,40,-1)\n",
    "\n",
    "#[reverse_word_map.get(OHE.active_features_[np.argmax(i)], '<m>') for i in one_hot_encoded_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ice sguardo honey honey honey honey hurricane pie pie honey pie pie honey honey honey honey pie pie honey pie pie honey honey honey honey honey honey honey honey honey pie pie pie pie ice xzibit honey honey darlin honey\n",
      "do n't need a crystal ball for me to see clearly eos no astrology or tarot cards eos watching cnn and holding my breath eos to face the daily news scares me to death eos i 'm pessi-mystic eos i\n",
      "do n't need a crystal ball <m> me to see clearly eos no <m> or tarot cards eos watching cnn and holding my breath eos to face the daily news scares <m> to death eos i 'm pessi-mystic eos i\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 10\n",
    "# def categorical_to_one_hot(categorical):\n",
    "#     return OHE.transform(categorical.reshape(batch_size*text_length,1)).toarray().reshape(batch_size,text_length,-1)\n",
    "\n",
    "# indices_fake = np.random.randint(0, X.shape[0], size=10)\n",
    "# fake_unfilled = X[indices_fake, :]\n",
    "# #noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "# fake_unfilled = categorical_to_one_hot(fake_unfilled)\n",
    "# fake_filled = generator_model.predict(fake_unfilled)\n",
    "# print(' '.join([reverse_word_map.get(OHE.active_features_[np.argmax(i)], '<m>') for i in fake_filled[0]]))\n",
    "# print(' '.join([reverse_word_map.get(i) for i in X_filled[indices_fake][0]]))\n",
    "# print(' '.join([reverse_word_map.get(i) for i in X[indices_fake][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#x = pd.read_csv(\"len40_mask3.txt\", header=None, delim_whitespace=True, dtype=str, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = 40\n",
    "vocab_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (text_length, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le = LabelEncoder()\n",
    "#categorical = le.fit_transform(x.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i for i in x.values.flatten() if not isinstance(i, str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = Tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.fit_on_sequences(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.sequences_to_matrix([[\"Hello\", \"this\", \"is\", \"test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.word_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer(filters='\\n', num_words=vocab_size) #try setting vocab_size to 2000 or 4000 if training not working\n",
    "with open(\"len40.txt\") as f:\n",
    "    t.fit_on_texts([f.read(), '<m>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "with open(\"len40_mask3.txt\") as f:\n",
    "    for line in f:\n",
    "        X.append(t.texts_to_sequences([line])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) #turn our data from python list of lists into np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled = []\n",
    "with open(\"len40.txt\") as f:\n",
    "    for line in f:\n",
    "        X_filled.append(t.texts_to_sequences([line])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled = np.array(X_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import Counter\n",
    "#Counter([len(p) for p in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OHE = OneHotEncoder()\n",
    "OHE.fit(np.array(list(t.word_index.values())).reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE.transform(X_filled[0].reshape((-1,1))).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, t.word_index.items())) #turn our numbers into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-1d51eab0c643>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mreverse_word_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int32' object is not iterable"
     ]
    }
   ],
   "source": [
    "[reverse_word_map[i] for i in X[0]] #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vocab_size is None:\n",
    "    vocab_size = len(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.add(Embedding(vocab_size, 300, input_length=text_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.add(Bidirectional(LSTM(300, return_sequences=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.add(TimeDistributed(Dense(vocab_size, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.add(Embedding(vocab_size, 300, input_length=text_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input_g = Input(shape=(text_length,vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_layer = Embedding(vocab_size, 300, input_length=text_length)\n",
    "embedding_layer = TimeDistributed(Dense(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embedding_layer(main_input_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Bidirectional(LSTM(300, return_sequences=True))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_output_g = TimeDistributed(Dense(vocab_size, activation='softmax'))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model = Model(inputs=[main_input_g], outputs=[main_output_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40, 97491)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 300)           29247600  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40, 600)           1442400   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 40, 97491)         58592091  \n",
      "=================================================================\n",
      "Total params: 89,282,091\n",
      "Trainable params: 89,282,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input_d = Input(shape=(text_length,vocab_size))\n",
    "aux_input_d = Input(shape=(text_length,vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_in = embedding_layer(main_input_d)\n",
    "context = embedding_layer(aux_input_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = Concatenate(axis=-1)([filled_in, context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Bidirectional(LSTM(300, return_sequences=True))(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_output_d = TimeDistributed(Dense(1, activation='sigmoid'))(x) #or sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model = Model(inputs = [main_input_d, aux_input_d], outputs=[main_output_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 40, 97491)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 40, 97491)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 40, 300)      29247600    input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 40, 600)      0           time_distributed_1[3][0]         \n",
      "                                                                 time_distributed_1[4][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 40, 600)      2162400     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 40, 1)        601         bidirectional_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 31,410,601\n",
      "Trainable params: 31,410,601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 40, 97491)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 40, 97491)    89282091    input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 40, 1)        31410601    model_1[3][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 91,445,092\n",
      "Trainable params: 91,445,092\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#AM = Sequential()\n",
    "optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "AM_input = Input(shape=(text_length,vocab_size))\n",
    "generator_output = generator_model(AM_input)\n",
    "discriminator_output = discriminator_model([generator_output, AM_input])\n",
    "AM = Model(inputs=[AM_input], outputs=discriminator_output)\n",
    "#AM.add(discriminator_model)\n",
    "AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "    metrics=['accuracy'])\n",
    "AM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def train(train_steps=2000, batch_size=10, save_interval=0):\n",
    "    def categorical_to_one_hot(categorical):\n",
    "        return OHE.transform(categorical.reshape(batch_size*text_length,1)).toarray().reshape(batch_size,text_length,-1)\n",
    "    noise_input = None\n",
    "    if save_interval>0:\n",
    "        noise_input = np.random.normal(0, 1, size=[16, 100])\n",
    "    for i in range(train_steps):\n",
    "        if i%2 == 0:\n",
    "            gc.collect()\n",
    "            print(i)\n",
    "        indices_fake = np.random.randint(0, X.shape[0], size=batch_size)\n",
    "        fake_unfilled = X[indices_fake, :]\n",
    "        #noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "        fake_unfilled = categorical_to_one_hot(fake_unfilled)\n",
    "        fake_filled = generator_model.predict(fake_unfilled)\n",
    "\n",
    "        indices_real = np.random.randint(0, X.shape[0], size=batch_size)\n",
    "        real_unfilled = X[indices_real, :]\n",
    "        real_filled = X_filled[indices_real, :]\n",
    "        real_unfilled = categorical_to_one_hot(real_unfilled)\n",
    "        real_filled = categorical_to_one_hot(real_filled)\n",
    "        \n",
    "        x_unfilled = np.concatenate((real_unfilled, fake_unfilled))\n",
    "        x_filled = np.concatenate((real_filled, fake_filled))\n",
    "        y = np.ones([2*batch_size, text_length, 1])\n",
    "        y[batch_size:, :, :] = 0\n",
    "        d_loss = discriminator_model.train_on_batch([x_filled, x_unfilled], y)\n",
    "        #above here is training the discriminator (DM)\n",
    "        #under here is training the generator (AM)\n",
    "        y = np.ones([batch_size, text_length, 1])\n",
    "        #noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "        indices_fake = np.random.randint(0, X.shape[0], size=batch_size)\n",
    "        fake_unfilled = X[indices_fake, :]\n",
    "        fake_unfilled = categorical_to_one_hot(fake_unfilled)\n",
    "        a_loss = AM.train_on_batch(fake_unfilled, y)\n",
    "        log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "        log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "        print(log_mesg)\n",
    "        #if save_interval>0:\n",
    "        #    if (i+1)%save_interval==0:\n",
    "        #        self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "        #            noise=noise_input, step=(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0: [D loss: 5.057300, acc: 0.500000]  [A loss: 0.000603, acc: 1.000000]\n",
      "1: [D loss: 3.780329, acc: 0.550000]  [A loss: 0.061261, acc: 0.975000]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "\n",
    "discriminator_model.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_fake = np.random.randint(0, X.shape[0], size=10)\n",
    "fake_unfilled = X[indices_fake, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_unfilled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ran',\n",
       " 'eos',\n",
       " 'just',\n",
       " 'to',\n",
       " 'find',\n",
       " 'the',\n",
       " 'road',\n",
       " 'had',\n",
       " 'ended',\n",
       " 'eos',\n",
       " 'just',\n",
       " 'where',\n",
       " 'it',\n",
       " 'began',\n",
       " 'eos',\n",
       " 'the',\n",
       " 'next',\n",
       " 'man',\n",
       " '<m>',\n",
       " 'i',\n",
       " 'marry',\n",
       " 'eos',\n",
       " 'there',\n",
       " 'ai',\n",
       " \"n't\",\n",
       " 'nothin',\n",
       " \"'\",\n",
       " 'he',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'do',\n",
       " 'eos',\n",
       " 'most',\n",
       " 'likely',\n",
       " '<m>',\n",
       " 'me',\n",
       " '<m>',\n",
       " 'much',\n",
       " 'eos',\n",
       " 'the']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_test = OHE.transform(fake_unfilled.reshape(400,1)).toarray().reshape(10,40,-1)\n",
    "\n",
    "[reverse_word_map.get(OHE.active_features_[np.argmax(i)], '<m>') for i in one_hot_encoded_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
